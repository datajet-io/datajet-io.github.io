<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>datajet - Personalized search and recommendation technologies</title>
    <description>datajet helps your’s customers discovery products they love using its search and recommendation technology
</description>
    <link>http://datajet.io/</link>
    <atom:link href="http://datajet.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 08 Oct 2015 15:21:47 +0200</pubDate>
    <lastBuildDate>Thu, 08 Oct 2015 15:21:47 +0200</lastBuildDate>
    <generator>Jekyll v2.5.3</generator>
    
      <item>
        <title>One year with Apache Mesos - The Good, The Bad, and the Ugly</title>
        <description>&lt;p&gt;We chose &lt;a href=&quot;http://mesos.apache.org&quot;&gt;Apache Mesos&lt;/a&gt; as the backbone of our infrastructure, &lt;a href=&quot;http://datajet.io/Building-infrastructure-for-a-real-time-search-and-recommendation-platform-post.html&quot;&gt;to serve a global customer base&lt;/a&gt; and solve some of the technical challenges we faced from our microservice-oriented architecture. These challenges were instrumenting diverse execution environment as well as, service discovery and deployment. Getting hardware provisioned and setting up a deployment process was always a necessary evil to get our stuff out the door and Mesos promised us to solve these issues.&lt;/p&gt;

&lt;p&gt;We use our infrastructure to log millions of events like product views and purchases daily and serve search and recommendation results from our APIs. After running Mesos in production for about a year we thought it would be a good time to reflect on the things we learned so far.&lt;/p&gt;

&lt;h2 id=&quot;the-good---releasing-a-new-service&quot;&gt;The Good - Releasing a (new) service&lt;/h2&gt;
&lt;p&gt;Pre-Mesos we had to prepare the necessary execution environments from testing to production and everything in between. Using Docker alongside Mesos allows us to encapsulate execution environments inside the container. That frees us from the effort of provisioning the infrastructure of every new microservice we want to release.&lt;/p&gt;

&lt;p&gt;Our release process initially consisted of pushing to a service’s git release branch, which automatically triggered the continuous integration process. &lt;a href=&quot;https://mesosphere.github.io/marathon&quot;&gt;Marathon&lt;/a&gt; serves as deployment manager. In coordination with Mesos it allocates a suitable machine for the service, and deploys it by pulling it from our private Docker hub onto the allocated machine.&lt;/p&gt;

&lt;p&gt;However, for external software like ElasticSearch we have no need for continuous integration and we release them directly from our local dev environment. To handle this use case we developed Shovel, which we plan to open-source shortly. It automates the process from building the Docker image containing the microservice to finally releasing them to the public. To release a microservice today we only have to prepare a Dockerfile and provide basic configuration. The basic configuration includes settings like public URL endpoint or amount of required CPU and memory resources. The rest of the release process is then completely handled by Shovel. To further simplify bootstrapping, we have a service template that contains commonly used components and allows us release a new microservice in minutes.&lt;/p&gt;

&lt;h2 id=&quot;the-bad---version-dependencies&quot;&gt;The Bad - Version dependencies&lt;/h2&gt;
&lt;p&gt;Mesos is still in its early days, probably best exemplified by the very sub-1.0 version numbers. New Mesos releases often include important bug fixes but upgrading has been a pain point for us due to the number of moving parts that led to catch-22 situations.&lt;/p&gt;

&lt;p&gt;As an example, we experienced &lt;a href=&quot;https://github.com/docker/docker/issues/9139&quot;&gt;memory leaks with Docker 1.6&lt;/a&gt; but were &lt;a href=&quot;https://issues.apache.org/jira/browse/MESOS-2986&quot;&gt;not able to upgrade&lt;/a&gt; for some time even though the bug got fixed in Docker 1.8. Upgrading Docker would have required upgrading to a Mesos version (0.23) that was &lt;a href=&quot;https://github.com/mesosphere/marathon/releases/tag/v0.10.0&quot;&gt;untested with Marathon version 0.10&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;the-ugly---stateful-services&quot;&gt;The Ugly - Stateful Services&lt;/h2&gt;
&lt;p&gt;Our search and recommendation services rely extensively on ElasticSearch. Therefore we deployed Elasticsearch running on Marathon as we do with our microservices. The promise of upgrading by just deploying a new Docker image and scaling-up by increasing the instance count in Marathon sounded very enticing. However, we later regretted making this decision and deployed subsequent stateful software like Apache Kafka not on Mesos.&lt;/p&gt;

&lt;p&gt;On several occasions healthy ElasticSearch nodes were restarted by Marathon which often resulted in partial downtime of our service. After some investigation we found out that the issue occurs due to &lt;a href=&quot;https://github.com/mesosphere/marathon/issues/1553&quot;&gt;a failure to reconcile the running application state on Marathon master failover&lt;/a&gt;. The issue was solved in the latest stable release but gracefully shutting down (stateful) services remains &lt;a href=&quot;https://github.com/mesosphere/marathon/issues/712&quot;&gt;a pain point of Marathon&lt;/a&gt; that has not been solved yet.&lt;/p&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s next?&lt;/h2&gt;

&lt;p&gt;Despite the hurdles we experienced, we never regretted the decision of choosing Mesos. It allows us to easily prototype and iterate on our search and recommendation services since the cost of releasing new services is negligible. We’re also looking forward to reaping the benefits of better resource utilization as we grow. Mesos’ eco-system has a vibrant community with rapid release cycles, and major challenges like running stateful services are being actively addressed with dynamic reservation and persistent volumes.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;We’re hiring!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Build infrastructure that handles billions of API calls or crunch terabytes of data to help people discover products they love. Drop us a line at &lt;a href=&quot;&amp;#109;&amp;#097;&amp;#105;&amp;#108;&amp;#116;&amp;#111;:&amp;#116;&amp;#101;&amp;#097;&amp;#109;&amp;#064;&amp;#100;&amp;#097;&amp;#116;&amp;#097;&amp;#106;&amp;#101;&amp;#116;&amp;#046;&amp;#105;&amp;#111;&quot;&gt;&amp;#116;&amp;#101;&amp;#097;&amp;#109;&amp;#064;&amp;#100;&amp;#097;&amp;#116;&amp;#097;&amp;#106;&amp;#101;&amp;#116;&amp;#046;&amp;#105;&amp;#111;&lt;/a&gt; if you like to join the fun.&lt;/p&gt;
</description>
        <pubDate>Thu, 08 Oct 2015 00:00:00 +0200</pubDate>
        <link>http://datajet.io/One-year-with-Apache-Mesos-The-Good-The-Bad-and-the-Ugly.html</link>
        <guid isPermaLink="true">http://datajet.io/One-year-with-Apache-Mesos-The-Good-The-Bad-and-the-Ugly.html</guid>
        
        
      </item>
    
      <item>
        <title>Building infrastructure for a real-time search and recommendation platform</title>
        <description>&lt;p&gt;At datajet we are logging 182 million requests daily, stemming from interactions like product views and purchases on our customer’s sites and apps. We use these events to power algorithms that optimize the relevancy of our search results and product recommendations.&lt;/p&gt;

&lt;p&gt;We built our first prototype in September 2014 consisting of a two server setup, one for data collection and crunching, and one for serving our first search service. &lt;a href=&quot;http://glinden.blogspot.de/2006/11/marissa-mayer-at-web-20.html&quot;&gt;Speed is paramount for eCommerce&lt;/a&gt; and search in particular, so we deployed our services on metal in our customer’s data centers to minimize network delays. The latter can be huge (~300-600ms) if you have a globally distributed customer base like ours. However, deploying our apps “locally” increased deployment complexity considerably. Our customer base grew and so did the diversity of server operating systems we needed to support in testing and deployment.&lt;/p&gt;

&lt;h2 id=&quot;containerize-and-awsize-all-the-things&quot;&gt;Containerize and AWSize all the things&lt;/h2&gt;

&lt;p&gt;The first step to minimize this complexity was using Docker containers for deployments to abstract away the differences of the underlying server operating systems. This made our life easier but not simple. Frequently our services would be affected by maintenance on our customer’s hardware. Also some customers were using older CentOS distributions that needed special attention to get Docker up and running.&lt;/p&gt;

&lt;p&gt;Finally we decided to move to the Amazon’s AWS platform to a have homogenous platform for our services. We chose AWS over Google mainly for the clearer documentation on data center location. This allowed us to pick a location that would be close to our customer’s data center to minimize network delays and respect data privacy requirements which highly depended on the legal framework our customers operated in.&lt;/p&gt;

&lt;h2 id=&quot;containerized-complexity&quot;&gt;Containerized complexity&lt;/h2&gt;

&lt;p&gt;While Docker improved our deployment process considerably, orchestrating even just a small number of containers comes &lt;a href=&quot;https://valdhaus.co/writings/docker-misconceptions/&quot;&gt;with its own challenges&lt;/a&gt;. Just a year ago the number of Docker orchestration options were scarce. &lt;a href=&quot;http://docs.aws.amazon.com/AmazonECS/latest/developerguide/Welcome.html&quot;&gt;EC2 container service&lt;/a&gt; was in private beta, &lt;a href=&quot;http://kubernetes.io/&quot;&gt;Google’s Kubernetes&lt;/a&gt; was still in stealth mode and others like &lt;a href=&quot;https://coreos.com/using-coreos/containers/&quot;&gt;CoreOS Quay&lt;/a&gt;, or &lt;a href=&quot;https://docs.docker.com/compose/&quot;&gt;Docker’s own solution&lt;/a&gt; were not available yet. Over the course of 2015 the number of options increased steadily and there does not seem to be a company that is &lt;a href=&quot;https://www.quora.com/What-is-the-best-Docker-Linux-Container-orchestration-tool&quot;&gt;either offering an orchestration solution as service or open-sourcing its inhouse tech&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;apache-mesos-to-the-rescue&quot;&gt;Apache Mesos to the rescue&lt;/h2&gt;

&lt;p&gt;Still, in November 2014 we were left with the option of hand-wiring our own solution or using something like &lt;a href=&quot;http://mesos.apache.org/&quot;&gt;Apache Mesos&lt;/a&gt; that was already being put through its paces at Twitter or Airbnb. However, we had some concerns of over-engineering since our number of servers was far from being in the hundreds. Also vanilla Mesos required hand-wiring a lot of custom parts to handle actual deployment. Luckily we came across &lt;a href=&quot;https://github.com/mesosphere/marathon&quot;&gt;Mesosphere’s Marathon&lt;/a&gt; and have been running it along with Mesos for almost a year now successfully in production. We will share our learnings from using them in our next blog post.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;We’re hiring!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Build infrastructure that handles billions of API calls or crunch terabytes of data to help people discover products they love. Drop us a line at &lt;a href=&quot;&amp;#109;&amp;#097;&amp;#105;&amp;#108;&amp;#116;&amp;#111;:&amp;#116;&amp;#101;&amp;#097;&amp;#109;&amp;#064;&amp;#100;&amp;#097;&amp;#116;&amp;#097;&amp;#106;&amp;#101;&amp;#116;&amp;#046;&amp;#105;&amp;#111;&quot;&gt;&amp;#116;&amp;#101;&amp;#097;&amp;#109;&amp;#064;&amp;#100;&amp;#097;&amp;#116;&amp;#097;&amp;#106;&amp;#101;&amp;#116;&amp;#046;&amp;#105;&amp;#111;&lt;/a&gt; if you like to join the fun.&lt;/p&gt;
</description>
        <pubDate>Fri, 02 Oct 2015 00:00:00 +0200</pubDate>
        <link>http://datajet.io/Building-infrastructure-for-a-real-time-search-and-recommendation-platform.html</link>
        <guid isPermaLink="true">http://datajet.io/Building-infrastructure-for-a-real-time-search-and-recommendation-platform.html</guid>
        
        
      </item>
    
  </channel>
</rss>
